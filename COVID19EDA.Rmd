---
title: "Exploratory Data Analysis - COVID19 in the United States (2020-2023)"
author: "Ricardo Morelli"
date: "2024-12-08"
output:
  html_document: default
  word_document: default
  pdf_document: default
---

# Purpose Statement

This paper outlines my approach to Exploratory Data Analysis (EDA), a systematic process I use to investigate ideas and develop understanding of a dataset. My methodology follows an iterative approach:

1. Generating questions about the data.
2. Using data transformation and visualisation to search for possible answers.
3. Leveraging any learnings to refine or generate new questions.

Rather than delving into advanced statistical concepts or modelling, this paper focuses on my personal approach and provides running commentary to highlight my thought process and decision-making approach when analysing a new dataset. In this example I will look at COVID19 in the United States, using data from covid19datahub.io courtesy of the 'COVID19' R package:


```{r Setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, message = FALSE, warning = FALSE, tidy = TRUE)
library(COVID19)
library(tidyverse)
library(snakecase)
library(scales)
library(ggrepel)
library(ggthemes)
library(viridis)
```

# Data Import & Variable Analysis

```{r Data Import, results = 'hide'}
# Data from covid19datahub.io

# Guidotti, E., Ardia, D., (2020), "COVID-19 Data Hub", Journal of Open Source Software 5(51):2376, doi: 10.21105/joss.02376

# Load in USA COVID19 data
covid19_usa <- covid19("United States", level = 2)
```

```{r Variable Exploration, eval = TRUE}
# Take a view of the variables in our dataset
glimpse(covid19_usa)
```

**Cumulative Numeric Variables**: confirmed, deaths, recovered...
  
- In isolation, these metrics are useful in creating dashboards or evaluating progress at a certain point in time. For my purposes, I will likely use these as inputs to create new variables.

- Additionally, it is possible to 'de-cum' these variables to calculate daily values such as 'new confirmed cases' or 'new deaths'. This approach will be useful if I choose to analyse trends across different points in time.

**Non-Cumulative Numeric Variables**: hosp, icu, vent

- These variables are immediately useful as they are non-cumulative and well suited for time series analysis. However, since these absolute values pertain to specific states, it may be more useful to transform them into proportions of the population, enabling comparisons across states.

**Population**: This variable is extremely useful as a denominator for calculating proportions with other numeric variables. It represents the population of a given state, not the entire United States (US).

**Policy Measure Variables**: school_closing, workplace_closing, stay_home_restrictions...

- Although these variables are represented as integers (0, 1, 2 ...etc), they should be treated as factors. This will be addressed in the next section.

- An immediate concern is the potential inconsistency in meaning across regions. For example, a level 2 'facial coverings' policy in New York may differ significantly from the same level in Florida. For this reason, I am hesitant to rely on these variables unless comparing regions governed by the same local or state policies.

**Government Response Indices**: stringency_index, economic_support_index...

- These Oxford response trackers provide a reliable basis for comparing countries or regions. Since these are calculated as an index rather than grouped into discrete levels, they offer greater assurance of capturing small differences between regions more accurately.

**Administrative Areas**: state, region...

- These are likely the most important set of variables, as most of the data will be grouped by State.

- No major transformation is required aside from renaming the variable for clarity.

**Coordinates & ISO codes**:

- These global standard measures are useful for any mapping visualisations.


# Data Cleaning & Subsetting

```{r Cleaning}
# Clean up column names
names(covid19_usa) <- to_snake_case(names(covid19_usa))

# Rename ambiguous columns
covid19_usa <- 
  covid19_usa |>
  rename(
    country = administrative_area_level_1,
    state = administrative_area_level_2
  ) 

# Remove non-mainland states/regions (and D.C)
covid19_usa <- 
  covid19_usa |> 
  filter(! state %in% c('American Samoa', 'Puerto Rico', 'Guam', 'Virgin Islands', 'Northern Mariana Islands', 'District of Columbia'))

# Subset data (I will focus on the first 3 years of COVID19 only).
covid19_usa <-
  covid19_usa |> 
  filter(date < '2023-01-01')

# Transform numerical variables to factors where appropriate:
fct_cols <- c('school_closing', 'workplace_closing', 'cancel_events', 'gatherings_restrictions',
              'transport_closing', 'stay_home_restrictions', 'internal_movement_restrictions',
              'international_movement_restrictions', 'information_campaigns', 'testing_policy',
              'contact_tracing', 'facial_coverings', 'vaccination_policy', 'elderly_people_protection')

covid19_usa <- 
  covid19_usa |> 
  mutate_at(fct_cols, factor)
```

```{r Create State_Data df}
# Create a new data frame to reference data not included in the COVID19 package.
state_data <- tibble::tribble(
  ~state,          ~abbreviation,     ~government_party,    ~area_kmsq,
  "Alabama",       "AL",              "Republican",         "135767",
  "Alaska",        "AK",              "Republican",         "1723337",
  "Arizona",       "AZ",              "Democratic",         "295234",
  "Arkansas",      "AR",              "Republican",         "137732",
  "California",    "CA",              "Democratic",         "423967",
  "Colorado",      "CO",              "Democratic",         "269601",
  "Connecticut",   "CT",              "Democratic",         "14357",
  "Delaware",      "DE",              "Democratic",         "6446",
  "Florida",       "FL",              "Republican",         "170312",
  "Georgia",       "GA",              "Democratic",         "153910",
  "Hawaii",        "HI",              "Democratic",         "28313",
  "Idaho",         "ID",              "Republican",         "216443",
  "Illinois",      "IL",              "Democratic",         "149995",
  "Indiana",       "IN",              "Republican",         "94326",
  "Iowa",          "IA",              "Republican",         "145746",
  "Kansas",        "KS",              "Republican",         "213100",
  "Kentucky",      "KY",              "Republican",         "104656",
  "Louisiana",     "LA",              "Republican",         "135659",
  "Maine",         "ME",              "Democratic",         "91633",
  "Maryland",      "MD",              "Democratic",         "32131",
  "Massachusetts", "MA",              "Democratic",         "27336",
  "Michigan",      "MI",              "Democratic",         "250487",
  "Minnesota",     "MN",              "Democratic",         "225163",
  "Mississippi",   "MS",              "Republican",         "125438",
  "Missouri",      "MO",              "Republican",         "180540",
  "Montana",       "MT",              "Republican",         "380831",
  "Nebraska",      "NE",              "Republican",         "200330",
  "Nevada",        "NV",              "Democratic",         "286380",
  "New Hampshire", "NH",              "Democratic",         "24214",
  "New Jersey",    "NJ",              "Democratic",         "22591",
  "New Mexico",    "NM",              "Democratic",         "314917",
  "New York",      "NY",              "Democratic",         "141297",
  "North Carolina","NC",              "Republican",         "139391",
  "North Dakota",  "ND",              "Republican",         "183108",
  "Ohio",          "OH",              "Republican",         "116098",
  "Oklahoma",      "OK",              "Republican",         "181037",
  "Oregon",        "OR",              "Democratic",         "254799",
  "Pennsylvania",  "PA",              "Democratic",         "119280",
  "Rhode Island",  "RI",              "Democratic",         "4001",
  "South Carolina","SC",              "Republican",         "82933",
  "South Dakota",  "SD",              "Republican",         "199729",
  "Tennessee",     "TN",              "Republican",         "109153",
  "Texas",         "TX",              "Republican",         "695662",
  "Utah",          "UT",              "Republican",         "219882",
  "Vermont",       "VT",              "Democratic",         "24906",
  "Virginia",      "VA",              "Democratic",         "110787",
  "Washington",    "WA",              "Democratic",         "184661",
  "West Virginia", "WV",              "Republican",         "62756",
  "Wisconsin",     "WI",              "Democratic",         "169635",
  "Wyoming",       "WY",              "Republican",         "253335"
)

# Transform 'area_kmsq' to a numeric variable
state_data <- state_data |> 
  mutate(
    area_kmsq = as.numeric(area_kmsq)
    )

# Transform 'government_party' to a factor
state_data$government_party <- as.factor(state_data$government_party)
```


# A Starting Point - Mortality
The base dataset includes numerous cumulative and absolute values, which are not directly comparable across US states with differing population sizes.  To enable meaningful comparisons, I will derive new variables proportional to each stateâ€™s population.

This exploration focuses on mortality, defined as a proportion of deaths to confirmed cases, which I will express as a percentage (i.e. the percentage of confirmed cases resulting in death).

Before analysing the data, it is important to outline my goals and expectations. Doing so provides structure to my analysis and helps mitigate potential cognitive biases.

**What Do I Want to Know?**

1. How does population relate to mortality? 
2. Did some states observe disproportionately high or low mortality rates relative to their population?

**What Are My Assumptions?**

- States with larger populations are likely to experience higher  mortality rate on average. Since COVID is an airborne virus, higher population provides more opportunity for transmission.

```{r Population x Mortality 1}
# Create a scatterplot: population vs mortality rate grouped by US State
covid19_usa |>
  left_join(state_data, join_by(state)) |> 
  group_by(state, abbreviation) |> 
  mutate(
    mortality = (deaths / confirmed),
  ) |> 
  summarise(
    population = max(population, na.rm = TRUE),
    deaths = max(deaths, na.rm = TRUE),
    mortality = mean(mortality, na.rm = TRUE),
    .groups = 'drop'
  ) |> 
  ggplot(aes(x = population, y = mortality, size = deaths, label = abbreviation, colour = state)) +
  geom_point(alpha = 0.3) +
  geom_label_repel(size = 3, max.overlaps = 3, show.legend = FALSE) +
  scale_x_continuous(labels = comma) +
  scale_y_continuous(labels = scales::percent) +
  scale_size_continuous(labels = scales::unit_format(unit = "K", scale = 1e-3)) +
  guides(colour = "none") +
  labs(
    title = "COVID19 Mortality Rate by US State",
    caption = "Data from covid19datahub.io",
    x = "Population",
    y = "Mortality Rate",
    size = "Deaths"
  ) +
  theme(
    plot.title = element_text(colour = "black"),
    plot.subtitle = element_text(colour = "red"),
    panel.border = element_rect(color = "black", fill = NA)
  )
```

In the above chart, two clusters of results stand out as immediately interesting, I will highlight them on the plot:

```{r Population x Mortality 2}
# Define the clusters to highlight
northeast_state_cluster <- c('CT', 'NJ', 'NY', 'MA', 'MI', 'PA')
largest_pop_cluster <- c('FL', 'TX', 'CA')

# Highlight these clusters on the plot
covid19_usa |>
  left_join(state_data, join_by(state)) |> 
  group_by(state, abbreviation) |> 
  mutate(
    mortality = (deaths / confirmed),
  ) |> 
  summarise(
    population = max(population, na.rm = TRUE),
    deaths = max(deaths, na.rm = TRUE),
    mortality = mean(mortality, na.rm = TRUE),
    .groups = 'drop'
  ) |> 
  ggplot(aes(x = population, y = mortality, size = deaths,
             colour = if_else(abbreviation %in% c(northeast_state_cluster, largest_pop_cluster), state, ''), 
             label = if_else(abbreviation %in% c(northeast_state_cluster, largest_pop_cluster), abbreviation, ''))) +
  geom_point(alpha = 0.3) +
  geom_label_repel(size = 3, max.overlaps = 5, show.legend = FALSE) +
  scale_x_continuous(labels = comma) +
  scale_y_continuous(labels = scales::percent) +
  scale_size_continuous(labels = scales::unit_format(unit = "K", scale = 1e-3)) +
  guides(colour = "none") +
  labs(
    title = "COVID19 Mortality Rate by US State",
    caption = "Data from covid19datahub.io",
    x = "Population",
    y = "Mortality Rate",
    size = "Deaths"
  ) +
  theme(
    plot.title = element_text(colour = "black"),
    plot.subtitle = element_text(colour = "red"),
    panel.border = element_rect(color = "black", fill = NA)
  )
```

**Cluster 1: FL, TX & CA**

Relative to my expectations, the above plot illustrates that the more populated states have mortality rates in line with the average. I note these are the three most populous states in the country, which I initially expected may result in above average mortality. Could their ability to curb mortality be a result of better government support? Policy measures? Vaccine access? Or something far simpler?

**Cluster 2: The Northeastern States**

While not extreme outliers, it is notable that all states in this group belong to the same geographical region. What factors in the Northeast contribute to above-average mortality rates?

Investigating these clusters independently may seem logical, but what if they are more interconnected than they appear? 

Earlier, I noted my preference to avoid using cumulative or absolute values, as they limit the ability to make meaningful regional comparisons. However, by relying solely on population as a metric, I have strayed from that principle. To address this, I will transform population into a new metric suitable for state-to-state comparison: 'population density'.

**Population Density** = (population / area_kmsq) , expressed as 'people per square km'

```{r Population density x Mortality}
# Create a scatterplot: population density vs mortality rate grouped by US State

# The COVID19 package does not contain land area data, so I need to join to our standard state_data data frame that contains the land area in km(sq) for each state.

covid19_usa |>
  left_join(state_data, join_by(state)) |> 
  group_by(state, abbreviation) |> 
  mutate(
    mortality = (deaths / confirmed),
    pop_density = (population / area_kmsq)
  ) |> 
  summarise(
    deaths = max(deaths, na.rm = TRUE),
    mortality = mean(mortality, na.rm = TRUE),
    pop_density = mean(pop_density),
    .groups = 'drop'
  ) |> 
  ggplot(aes(x = pop_density, y = mortality, size = deaths, label = abbreviation, colour = state)) +
  geom_point(alpha = 0.3) +
  geom_label_repel(size = 3, max.overlaps = 5, show.legend = FALSE) +
  scale_x_continuous(labels = comma) +
  scale_y_continuous(labels = scales::percent) +
  scale_size_continuous(labels = scales::unit_format(unit = "K", scale = 1e-3)) +
  guides(colour = "none") +
  labs(
    title = "COVID19 Mortality Rate by US State",
    subtitle = "More densely populated states observed higher mortality rates on average",
    caption = "Data from covid19datahub.io",
    x = "Population Density (people per sq. km)",
    y = "Mortality Rate",
    size = "Deaths"
  ) +
  theme(
    plot.title = element_text(colour = "black"),
    plot.subtitle = element_text(colour = "red"),
    panel.border = element_rect(color = "black", fill = NA)
  )
```

The fit between these two variables is significantly better than when using population alone. This makes theoretical sense; the more people in any given space, the greater the likelihood that the virus will spread and as a result the increased chance of mutation into a more deadly variant. 

I have briefly examined the concept of mortality rate and the factors that contribute to variations in our observations. It is important to note that this analysis so far considers averages over a 3-year period (2020-2023). This static approach does not explore how mortality rate changes over time. Coronavirus is a rapidly changing phenomenon. From virus mutations to the availability of vaccines, no aspect of this pandemic has remained static. In the next section, I will focus on how mortality rates change **over time**.

# Mortality and the Passage of Time

Iâ€™m interested in understanding how mortality rates change over time, but I need to consider some important points:

1. Viruses take time to spread, patient zero cannot pass the virus to 100,000 others in a day, transmission rates increase over time.
2. Initially, public reaction to COVID19 was cautious and risk averse. In early 2020, the virus and its impacts were not fully known, leading many countries to enforce strict public health measures to reduce transmission.

Given these factors, the volume of data is uneven across the timeline, with many days in early 2020 containing NIL observations for some variables. This leads to sample size issues, for example look at the mortality rates for some of the days in early 2020:

```{r Small sample size example}
covid19_usa |> 
  group_by(date) |> 
  mutate(mortality = (deaths / confirmed)) |> 
  select(deaths, confirmed, mortality) |> 
  arrange(desc(mortality))
```

To address this issue and reduce extreme values during periods of low sample size, I will aggregate  the time series data into specific periods, such as months. This approach involves dividing the timeline into intervals (i.e. months) and calculating the average value of any given variable for each period.

**What Do I Want to Know?**

1. States in the northeast region observed the highest mortality rates in the country. Was this always the case?

2. Were there specific periods when mortality trended upward or downward across all states?

**What Are My Assumptions?**

1. I expect that mortality will trend down over time as the population develops layers of immunity, both natural and through vaccinations. This should result in a decrease in the marginal threat of each new case.

2. Mortality will reach an equilibrium level, assuming the following conditions are generally true:
- Most individuals will contract COVID19 at least once, and those who recover will survive future infections.
- Individuals who chose to be vaccinated will receive the vaccination.

**NOTE**: During exploratory data analysis, it is sometimes necessary to create visuals that may be complex or not be suitable for end-user consumption. In this case, I am plotting 50 line-graphs on a single plane. While this will not be visually appealing, it will serve its purpose in providing high level overview and identifying any outliers.

```{r Mortality over time geom_line}
# Create a line plot: mortality rate over time for each US state
covid19_usa |>
  left_join(state_data, join_by(state)) |> 
  group_by(month = lubridate::floor_date(date, "month"), state) |> 
  mutate(
    mortality = deaths / confirmed
  ) |> 
  summarise(
    deaths = max(deaths),
    mortality = mean(mortality, na.rm = TRUE),
    .groups = 'drop'
  ) |> 
  ggplot(aes(x = month, y = mortality, group = state, color = state)) +
  geom_line(size = 0.7, show.legend = FALSE) +
  scale_y_continuous(labels = scales::percent) +
  labs(
    title = "COVID19 Mortality Rate by US State",
    caption = "Data from covid19datahub.io",
    y = "Mortality Rate"
  ) +
  theme(
    axis.title.x = element_blank(),
    plot.title = element_text(colour = "black"),
    plot.subtitle = element_text(colour = "red"),
    panel.border = element_rect(color = "black", fill = NA),
    legend.position = c(0.85, 0.8),
    legend.title = element_blank()
  )
```

As expected, the above graph is messy and unsuitable for public consumption, though it remains useful for my analysis. I observe a clear downward trend, with the variation in observations amongst different states decreasing over time. A notable observation is the period in late 2021, where each state experienced a sharp decrease in mortality. What factors contributed to this occurrence? 

Before exploring further, it is important to examine the Northeastern states closely. Adding labels to this plot may not be effective. Therefore, I need to find an alternative visualisation type to better convey this information:

```{r Mortality over time geom_tile}
# Create a tile visual: mortality rate over time for each US state
covid19_usa |>
  group_by(month = lubridate::floor_date(date, "month"),state) |> 
  mutate(
    mortality = deaths / confirmed
  ) |> 
  summarise(
    mean_mortality = mean(mortality, na.rm = TRUE),
    .groups = 'drop'
  ) |>
  ggplot(aes(x = month, y = reorder(state, desc(state)), fill=mean_mortality)) +
  geom_tile() +
  scale_fill_viridis_c(labels = scales::label_percent()) +
  labs(
    title = "COVID19 Mortality Rate by US State",
    subtitle = "Visualising the change in Mortality Rate in each US state",
    caption = "Data from covid19datahub.io",
    fill = "Mortality Rate"
  ) +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    plot.title = element_text(colour = "black"),
    plot.subtitle = element_text(colour = "red"),
    panel.border = element_rect(color = "black", fill = NA)
  )
```

The above visualisation is more informative, allowing us to observe several key points:

- The northeastern cluster of states experienced above average mortality rate in 2020.
- From 2021 onwards, there is a noticeable absence of extreme values. All states observed a consistent decrease in mortality from this point.

What caused the significant drop in the mortality rates by the end of 2021? I will examine the most obvious variable: vaccines, and their relationship with mortality.

# Vaccination and its Impact on Mortality

Before I examine the relationship between vaccination and mortality, it is important to define how I will measure vaccination. The dataset contains a â€˜people_fully_vaccinatedâ€™ variable indicating the cumulative number of people who received all required doses prescribed by the vaccination protocol. 

However, this may vary between regions due to different vaccination protocols. To ensure consistency, I will create a standardised variable, 'average vaccine doses per person' by dividing the cumulative sum of vaccine doses administered by the population.

**Average Vaccine Doses Per Person** = (vaccines / population)

Regarding timelines, given the first vaccine in the US was administered in December 2020, the time frame for this part of the analysis will be limited to 2021-2023. The focus will be on the variability in mortality that can be attributed to vaccination, so the pre-vaccine period will not be included.

**What Do I Want to Know?**

1. How strong is the relationship between vaccination and mortality? Is there a point where we observe diminishing returns?
2. If vaccines were widely available from early 2021, why did the sharp fall in mortality happen almost 12 months later? Could this decrease be attributed to factors other than vaccination? 

**What Are My Assumptions?**

1. I expect to observe a mildly negative relationship between vaccination and mortality rate. The reason for using â€˜mildlyâ€™ is because there are numerous uncontrolled variables, some of which are beyond my capacity to control.
2. It is possible that some states exhibit both high mortality rates and high vaccination rates. This may be due to causational factors, where high mortality is an area prompts more people to get vaccinated.

```{r Vaccine doses x Mortality}
# Create a line plot: average vaccine doses vs mortality rate for each US state
covid19_usa |> 
  filter(date > '2021-01-01') |> 
  group_by(month = lubridate::floor_date(date, "month"), state) |> 
  mutate(
    mortality = (deaths / confirmed),
    vaccine_doses_pp = (vaccines / population)
  ) |> 
  summarise(,
    mortality = mean(mortality, na.rm = TRUE),
    vaccine_doses_pp = mean(vaccine_doses_pp, na.rm = TRUE),
    .groups = 'drop'
  ) |> 
  ggplot(aes(x = vaccine_doses_pp, y = mortality, group = state, color = state)) +
  geom_line(xintercept = 0.7) +
  scale_x_continuous(breaks = seq(0, 3, by = 0.5)) +
  scale_y_continuous(labels = scales::percent) +
  labs(
    title = "Relationship between vaccine doses and COVID19 mortality rate in the US",
    subtitle = "More vaccine doses per person resulted in a lower mortality rate on average",
    caption = "Data from covid19datahub.io",
    x = "Average Vaccine doses per person",
    y = "Mortality Rate"
  ) +
  theme(
    plot.title = element_text(colour = "black"),
    plot.subtitle = element_text(colour = "red"),
    panel.border = element_rect(color = "black", fill = NA),
    legend.position = "none"
  )
```

Not much additional information is provided in the above chart. Upon further consideration, the measure of average doses per person may not be as suitable as initially thought. For example, consider three people and three vaccine doses:

- Scenario 1: Each person receives (1) dose.
- Scenario 2: One person receives (2) doses, another receives (1) and the last person receives (0).

While the average doses per person are equal (1) in both scenarios, the actual impact on mortality will vary. Acknowledging this potential flaw, I will revert to using the â€˜people_fully_vaccinatedâ€™ variable, and compare it across all US states.

```{r Prop_full_vax x Mortality}
# Create a line plot: population vaccination percentage vs mortality rate.
covid19_usa |> 
  filter(date > '2021-01-01') |> 
  group_by(month = lubridate::floor_date(date, "month"), state) |> 
  mutate(
    mortality = (deaths / confirmed),
    prop_fully_vax = (people_fully_vaccinated / population)
  ) |> 
  summarise(,
            mortality = mean(mortality, na.rm = TRUE),
            prop_fully_vax = mean(prop_fully_vax, na.rm = TRUE),
            .groups = 'drop'
  ) |> 
  ggplot(aes(x = prop_fully_vax, y = mortality, group = state, color = state)) +
  geom_line() +
  geom_vline(xintercept = c(0.5, 0.6, 0.7, 0.8), linetype = 4) +
  scale_x_continuous(breaks = seq(0, 1, by = 0.1)) +
  scale_y_continuous(labels = scales::percent) +
  labs(
    title = "Tracking how COVID19 Mortality changes as a Population becomes Fully Vaccinated",
    subtitle = "Reaching certain vaccination thresholds appears to significantly reduce mortality rate",
    caption = "Data from covid19datahub.io",
    x = "Proportion of Population Fully Vaccinated",
    y = "Mortality Rate"
  ) +
  theme(
    plot.title = element_text(colour = "black"),
    plot.subtitle = element_text(colour = "red"),
    panel.border = element_rect(color = "black", fill = NA),
    legend.position = "none"
  )
```

In the above plot, I observe a significant difference in the rate of change (gradient) for mortality between the bands I have created. Unfortunately, until I quantify a trend it is nothing more than speculation. I will take this opportunity to move away from this visual; outside of trying to navigate between the 50 squiggly lines on this chart, its not entirely clear how the rate of change increases(decreases) between vaccination brackets. I'd like to compare the differences in average mortality when moving between the 50-60%, 60-70% and 70-80% brackets.

Here I observe a significant difference in the rate of change (gradient) for mortality between the bands I have created. However, until I quantify a trend it remains speculation.I will take this opportunity to move away from this visual as it is difficult to interpret the 50 lines on the chart and how the rate of change increases (decreases) between vaccination brackets. I propose comparing the differences in **average** mortality when moving between the 50-60%, 60-70% and 70-80% brackets.

**The Plan:** Calculate the mortality for each state at the 0.5, 0.6, 0.7 and 0.8 thresholds (noting that not all states will reach all thresholds). I will then join the four new data frames and calculate the average percentage change in mortality between each threshold.

```{r Percent change in mortality between vaccination thresholds}
# Calculate the mortality rate at the point in time that each state reached 50% full vaccination.
vax_50_60 <- covid19_usa |> 
  group_by(state) |> 
  mutate(
    mortality = (deaths / confirmed),
    prop_fully_vax = (people_fully_vaccinated / population)
  ) |> 
  filter(max(prop_fully_vax, na.rm = TRUE) >= 0.6) |>
  filter(min(prop_fully_vax, na.rm = TRUE) > 0) |> 
  filter(prop_fully_vax >= 0.5) |> 
  summarise(
    mortality_50 = mortality,
    prop_fully_vax_50 = prop_fully_vax
  ) |> 
  top_n(-1, prop_fully_vax_50)

# Repeat for the 60% threshold.
vax_60_70 <- covid19_usa |> 
  group_by(state) |> 
  mutate(
    mortality = (deaths / confirmed),
    prop_fully_vax = (people_fully_vaccinated / population)
  ) |> 
  filter(max(prop_fully_vax, na.rm = TRUE) >= 0.7) |>
  filter(min(prop_fully_vax, na.rm = TRUE) > 0) |> 
  filter(prop_fully_vax >= 0.6) |> 
  summarise(
    mortality_60 = mortality,
    prop_fully_vax_60 = prop_fully_vax
  ) |> 
  top_n(-1, prop_fully_vax_60)

# Repeat for the 70% threshold.
vax_70_80 <- covid19_usa |> 
  group_by(state) |> 
  mutate(
    mortality = (deaths / confirmed),
    prop_fully_vax = (people_fully_vaccinated / population)
  ) |> 
  filter(max(prop_fully_vax, na.rm = TRUE) >= 0.8) |>
  filter(min(prop_fully_vax, na.rm = TRUE) > 0) |> 
  filter(prop_fully_vax >= 0.7) |> 
  summarise(
    mortality_70 = mortality,
    prop_fully_vax_70 = prop_fully_vax
  ) |> 
  top_n(-1, prop_fully_vax_70)

# Repeat for the 80% threshold.
vax_80 <- covid19_usa |> 
  group_by(state) |> 
  mutate(
    mortality = (deaths / confirmed),
    prop_fully_vax = (people_fully_vaccinated / population)
  ) |> 
  filter(max(prop_fully_vax, na.rm = TRUE) >= 0.8) |>
  filter(min(prop_fully_vax, na.rm = TRUE) > 0) |> 
  filter(prop_fully_vax >= 0.8) |> 
  summarise(
    mortality_80 = mortality,
    prop_fully_vax_80 = prop_fully_vax
  ) |> 
  top_n(-1, prop_fully_vax_80)

# Join all results together and calculate the average % change in mortality rate between each threshold.
vax_all_bands <- vax_50_60 |> 
  left_join(vax_60_70, join_by(state)) |> 
  left_join(vax_70_80, join_by(state)) |> 
  left_join(vax_80, join_by(state)) |> 
  mutate(
    perc_change_50_60 = (mortality_60 - mortality_50) / (mortality_50),
    perc_change_60_70 = (mortality_70 - mortality_60) / (mortality_60),
    perc_change_70_80 = (mortality_80 - mortality_70) / (mortality_70)
  ) |> 
  select(perc_change_50_60, perc_change_60_70, perc_change_70_80)
```

```{r Percent change in mortality between vaccination thresholds (RESULTS)}
mean(vax_all_bands$perc_change_50_60, na.rm = TRUE)
mean(vax_all_bands$perc_change_60_70, na.rm = TRUE)
mean(vax_all_bands$perc_change_70_80, na.rm = TRUE)
```


I observe the following (relative) percent decreases in the average mortality rate between each vaccination threshold:

- 50% to 60% : -4.00%
- 60% to 70% : -9.30%
- 70% to 80% : -41.20%

The comparative rate of change between each bracket is noteworthy. Given the relative plateau up to the ~50% fully vaccinated mark, it is notable to see mortality decrease steeply afterwards. Throughout the vaccine campaign here in Victoria (Australia), the Department of Health emphasised the importance of reaching these vaccination thresholds, so it is pleasing to see that at there seems to be merit to the research, at least on an empirical level.

In the final section, there are two aspects I'd like to explore:

1. Previously, I used a messy visual to get an idea and contextualise some observations. How can I present these findings in a way that is fit for public consumption? I will examine how I can better communicate vaccination levels across each US state.
2. The current visual has an issue with representing â€˜timeâ€™, as each point on the x-axis covers multiple snapshots in time. To address this, it will be useful to show a new visual that represents how long it took each state to reach a given threshold. This will be more useful to users who wish to know how quickly their state became vaccinated relative to the rest of the country.

# A Colourful Finish

In this final part, I will use the vaccination ideas generated in the last section to create engaging user-friendly visuals. Letâ€™s start by taking each stateâ€™s current (end of 2022) vaccination rate and overlaying it on a map of the US.

```{r USA Vaccination Map}
# Calculate the current (31-Dec-2022) proportion of each state's population that is fully vaccinated.
us_vax_by_state <- covid19_usa |> 
  group_by(state) |> 
  mutate(
    prop_fully_vax = (people_fully_vaccinated / population)
  ) |> 
  summarise(
    prop_fully_vax = max(prop_fully_vax, na.rm = TRUE)
  )

# Use the 'maps' package as the basis for creating the visual
library(maps)

# Load in US state border data
us_map_data <- map_data('state') 
names(us_map_data) <- to_snake_case(names(us_map_data))

# Transform state titles to 'proper' form
us_map_data <- us_map_data |> 
  mutate(
    region  = str_to_title(region) 
  ) |> 
  rename(
    state = region)

# Join new data frames to the existing state_data table
us_map_all <- us_vax_by_state |> 
  left_join(us_map_data, join_by(state)) |> 
  left_join(state_data, join_by(state))

# Create a Map visual displaying the current 'prop_fully_vax' for each US state (Alaska & Hawaii removed for visual purposes)
us_vaccination_map <- us_map_all |> 
  filter(!state %in% c('Alaska', 'Hawaii')) |> 
  ggplot(aes(x = long, y = lat, group = state, fill = prop_fully_vax)) +
  geom_polygon(color = "black", linewidth = 0.2) +
  scale_fill_viridis_c(name = 'Prop. Full Vax') +
  coord_fixed(1.3) +
  labs(
    title = "Proportion of Population Fully Vaccinated By State",
    caption = "Data from covid19datahub.io"
  ) +
  theme(
    axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank(),
    axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank(),
    plot.title = element_text(colour = "black"),
    panel.background = element_blank()
  )

us_vaccination_map
```

The above map looks similar to something I've seen before... let's take a look at the 2020 election map:

```{r USA Vaccination Map + 2020 Election Map}
# Create a Map visual showing the results of the 2020 US election (Alaska & Hawaii removed for visual purposes)
us_2020_election_map <- us_map_all |> 
  filter(!state %in% c('Alaska', 'Hawaii')) |>
  ggplot(aes(x = long, y = lat, group = state, fill = government_party)) +
  geom_polygon(color = "black", linewidth = 0.2) +
  scale_fill_manual(values = c(Republican = "#E81B23", Democratic = "#00AEF3")) +
  coord_fixed(1.3) +
  labs(
    title = "2020 US Election Map"
  ) +
  theme(
    axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank(),
    axis.title.y = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank(),
    plot.title = element_text(colour = "black"),
    legend.title = element_blank(),
    panel.background = element_blank()
  )

# Use patchwork to compare the maps:
library(patchwork)
(us_vaccination_map / us_2020_election_map)
```

This comparison highlights that people living in democratic states are, on average, more likely to be fully vaccinated than those in republican states.

I will now address how to better illustrate the time taken to reach vaccination thresholds. Specifically, I will calculate how long it took each state to reach 80% full vaccination and explore the most engaging ways to visualise this information.

```{r Race to 80 Vaccination geom_line}
# Calculate each state's vaccination rate at each day from 2021 onwards (for those that reached 80%)
vax_race_80 <- covid19_usa |> 
  left_join(state_data, join_by(state)) |> 
  group_by(state, abbreviation) |> 
  mutate(
    prop_fully_vax = (people_fully_vaccinated / population)
  ) |> 
  filter(max(prop_fully_vax, na.rm = TRUE) >= 0.8) |>
  filter(min(prop_fully_vax, na.rm = TRUE) > 0) |> 
  filter(prop_fully_vax <= 0.8) |> 
  select(date, prop_fully_vax)

# Determine the endpoints (date that each state reached 80%)
data_ends_80 <- vax_race_80 |> 
  summarise(
    date_end = date,
    prop_vax_end = prop_fully_vax
  ) |> 
  slice_max(prop_vax_end, n = 1, with_ties = FALSE)

# Create a line plot: % Fully vaccinated over time, for states that reached 80%.
vax_race_80 |> 
  ggplot(aes(color = state, group = state, label = abbreviation)) +
  geom_point(data = data_ends_80, aes(x = date_end, y = prop_vax_end)) +
  geom_line(aes(x = date, y = prop_fully_vax)) +
  geom_segment(data = data_ends_80 |> filter(!state %in% c('Rhode Island', 'Massachusetts')), aes(x = date_end, y = prop_vax_end, xend = date_end, yend = (prop_vax_end + 0.1)), linetype = 5) +
  geom_segment(data = data_ends_80 |> filter(state %in% c('Rhode Island', 'Massachusetts')), aes(x = date_end, y = prop_vax_end, xend = date_end, yend = (prop_vax_end + 0.17)), linetype = 5) +
  geom_label(data = data_ends_80 |> filter(!state %in% c('Rhode Island', 'Massachusetts')), aes(x = date_end, y = prop_vax_end + 0.1)) +
  geom_label(data = data_ends_80 |> filter(state %in% c('Rhode Island', 'Massachusetts')), aes(x = date_end, y = prop_vax_end + 0.17)) +
  geom_hline(yintercept = 0.8, linetype = 4) + 
  scale_x_date(date_labels = "%b %y", date_breaks = "3 months") +
  scale_y_continuous(
    limits = c(0,1),breaks = seq(0, 1, by = 0.1),
    labels = scales::percent,
  ) +
  labs(
    title = "The Great (Vaccination) Race",
    subtitle = "Visualising the US states fastest to reach 80% vaccination rate",
    caption = "Data from covid19datahub.io",
    y = "% Fully Vaccinated",
    color = "State"
  ) +
  theme(axis.title.x = element_blank(),
        plot.title = element_text(colour = "black"),
        plot.subtitle = element_text(colour = "red"),
        panel.border = element_rect(color = "black", fill = NA),
        legend.position = "none"
  )

```

The above visual is effective and works well due the small number of states (7) that reached the 80% vaccination threshold. If I wanted to examine a lower threshold, such as 70%, which 20 states reach in 2023, a different visual may be more effective to prevent over-plotting:


```{r Race to 70 Vaccination geom_col}
# Calculate each state's vaccination rate at each day from 2021 onwards (for those that reached 70%)
vax_race_70 <- covid19_usa |> 
  left_join(state_data, join_by(state)) |> 
  group_by(state, abbreviation) |> 
  mutate(
    prop_fully_vax = (people_fully_vaccinated / population)
  ) |> 
  filter(max(prop_fully_vax, na.rm = TRUE) >= 0.7) |>
  filter(min(prop_fully_vax, na.rm = TRUE) > 0) |> 
  filter(prop_fully_vax <= 0.7) |> 
  select(date, prop_fully_vax)

# Determine the start points (date of first vaccination dose in each state)
data_starts_70 <- vax_race_70 |> 
  summarise(
    date_start = date,
    state,
    prop_vax_start = prop_fully_vax
  ) |>
  slice_min(prop_vax_start, n = 1, with_ties = FALSE)

# Determine the endpoints (date that each state reached 70%)
data_ends_70 <- vax_race_70 |> 
  summarise(
    date_end = date,
    prop_vax_end = prop_fully_vax
  ) |> 
  slice_max(prop_vax_end, n = 1, with_ties = FALSE)

# Merge start and endpoints together
days_to_70 <- merge(data_starts_70,data_ends_70,by=c("state")) |> 
  mutate(
    days = as.numeric(date_end - date_start)
  ) |> 
  arrange(days)

# Create a column chart: Days each state took to reach 70% full vaccination
days_to_70 |>
  ggplot(aes(x = days, y = fct_reorder(as.factor(state), -days), fill = days, label = days)) +
  geom_col(width = 0.7, color = "black", show.legend = FALSE) +
  geom_text(aes(label = days), hjust = -0.2) +
  scale_fill_gradient(low = "lightblue", high = "darkblue", na.value = NA) +
  scale_x_continuous() +
  scale_y_discrete() +
  labs(
    title = "Days to reach 70% full vaccination by US State",
    caption = "Data from covid19datahub.io",
    x = "Days"
  ) +
  theme(
    axis.title.y = element_blank(),
    plot.title = element_text(colour = "black"),
    plot.subtitle = element_text(colour = "red"),
    panel.border = element_rect(color = "black", fill = NA),
    panel.background = element_blank(),
    legend.title = element_blank()
  )
```

By using a column chart as detailed above, I can include more data in a similar sized space compared to the line plot. However, it sacrifices the ability to track each state's progress over time towards 70%. Deciding which visual to use requires considering what will be most useful for our audience.

The visual representation of vaccination data is crucial for effectively communicating the progress and achievements of public health initiatives. By carefully selecting the appropriate visual formats, I can ensure that the information is both engaging and informative. The choice of visualisation should be guided by the nature of the data and the needs of the audience, allowing for a clear and comprehensive understanding of the trends and milestones I am trying to communicate.
